{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenStreetMap Project - Data Wrangling with MongoDB\n",
    "#### Author: Yuheng Cai\n",
    "\n",
    "Map Area: Hongkong, China\n",
    "\n",
    "References:\n",
    "1. Mapzen.com to extract area map data: https://s3.amazonaws.com/metro-extracts.mapzen.com/hong-kong_china.osm.bz2\n",
    "2. Characters in key: https://taginfo.openstreetmap.org/reports/characters_in_keys\n",
    "3. Why doesn't Honghkong have postal code: https://www.quora.com/Why-doesnt-Hong-Kong-have-postal-codes\n",
    "\n",
    "Source code:  data_wrangling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Problems Encountered in the Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hongkong OSM data was selected for the project given that I live around Hongkong area and more familiar with it.\n",
    "\n",
    "Before the Hongkong OSM data was transformed to a predefined data model and imported to MongoDB, the data cleaning process was conducted, during which following problems were identifed:\n",
    "* Street names are not standardized (some acronyms were used i.e. AVE, Rd, St)\n",
    "* Upper case key used in 'tag' tag (not compliant with convention according to References[2]\n",
    "* Both British and American English were used in 'color' key (i.e ‘colour/color'）\n",
    "* Name key consists of multiple forms (i.e. \"name\", \"name:zh\", \"name:en\", each of which refers to name in different languages)\n",
    "* Phone format is not consistent (some with +country/area code; others without)\n",
    "\n",
    "Note: postal code is seldom(if not never) used in Hongkong. Please refer to References[3] for some forum discussion. Previous review feedback/suggestion on doing some wrangling with postal code is not relevant for Hongkong OSM data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Street Name Not Standardized\n",
    "\n",
    "Python code (data_wrangling.py) converts all 'non-standard' street names based on following mapping before getting imported to MongoDB:  \n",
    "street_mapping = {  \n",
    "\t\t\t\"St\": \"Street\",  \n",
    "\t\t\t\"AVE\": \"Avenue\",  \n",
    "\t\t\t\"Rd\": \"Road\"  \n",
    "\t\t\t}  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upper case keys in tag\n",
    "By convention(References[2]), characters in key should be in lower case. This issue was simply addressed by applying lower case funciton to the key during the parsing and data model transformation process in Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color key in both British and American English\n",
    "Similar to the approach addressing the street name issue mentioned above, color keys were standardized to uniform 'color' during the parsing and data model transformation process in Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple forms for Name key\n",
    "My interpretation for the Hongkong area OSM data having name keys in multiple forms such as \"name\", \"name:zh\", \"name:en\" is due to the fact that Chinese and English (potentially other languages as well) are well accepted in Hongkong. Instead of doing data cleaning, a better approach is to transform these data into a better model so as to capture this kind of information and put them under a dictionary such as below:  \n",
    "{\"name\":  \n",
    "    {\"default\": \"default name\",  \n",
    "     \"en\": \"english name\",  \n",
    "     \"zh\": \"chinese name\"  \n",
    "     }  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phone Number\n",
    "Some 'nodes' in Hongkong area OSM data contain phone number in standard format with '+country/area' code; others don't. Cleaning was done by using regular express to find those without '+country/area' and add them into the transformed data model (update_phone function in data_wrangling.py).  \n",
    "For example:  \n",
    "34282828  => +852 3428 2828  \n",
    "2809 4426 => +852 2809 4426"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Overview of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains basic statistics about the dataset and the MongoDB queries used to gather them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### File sizes\n",
    "                                                \n",
    "hong-kong_china.osm.............504 MB  \n",
    "hong-kong_china.osm.json.... 584 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Documents\n",
    "\n",
    "> db.hongkong.find().count()  \n",
    "2681824"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Nodes\n",
    "\n",
    "> db.hongkong.find({'type':'node'}).count()  \n",
    "2445872"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Ways\n",
    "> db.hongkong.find({\"type\":\"way\"}).count()  \n",
    "233798"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Unique Users\n",
    "> db.hongkong.distinct(\"created.user\").length  \n",
    "1471"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 Contributing Users\n",
    "> db.hongkong.aggregate([{\"$group\":{\"_id\":\"$created.user\", \"count\":{\"$sum\":1}}}, {\"$sort\":{\"count\":-1}}, {\"$limit\":10}])  \n",
    "{ \"_id\" : \"hlaw\", \"count\" : 509012 }  \n",
    "{ \"_id\" : \"MarsmanRom\", \"count\" : 236477 }  \n",
    "{ \"_id\" : \"Popolon\", \"count\" : 162804 }  \n",
    "{ \"_id\" : \"Rebecca114\", \"count\" : 121009 }  \n",
    "{ \"_id\" : \"sn0wblind\", \"count\" : 102497 }  \n",
    "{ \"_id\" : \"fsxy\", \"count\" : 100588 }  \n",
    "{ \"_id\" : \"katpatuka\", \"count\" : 97674 }  \n",
    "{ \"_id\" : \"fdulezi\", \"count\" : 80073 }  \n",
    "{ \"_id\" : \"KX675\", \"count\" : 77980 }  \n",
    "{ \"_id\" : \"rainy3519446\", \"count\" : 58229 }  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minority users contributes most data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Documents without Data Source\n",
    "> db.hongkong.find({\"source\": {\"$exists\": 0}}).count()  \n",
    "2667657"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 Data Sources\n",
    "> db.hongkong.aggregate([{\"$group\":{\"_id\":\"$source\", \"count\":{\"$sum\":1}}}, {\"$sort\":{\"count\":-1}}, {\"$limit\":5}])  \n",
    "{ \"_id\" : null, \"count\" : 2667657 }  \n",
    "{ \"_id\" : \"bing\", \"count\" : 4214 }  \n",
    "{ \"_id\" : \"GPS\", \"count\" : 3549 }  \n",
    "{ \"_id\" : \"Bing\", \"count\" : 1429 }  \n",
    "{ \"_id\" : \"Yahoo hires\", \"count\" : 1417 }  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of data source is unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 appearing shop types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> db.hongkong.aggregate([{\"$match\":{\"shop\":{\"$exists\":1}}}, {\"$group\": {\"_id\":\"$shop\", \"count\":{\"$sum\":1}}}, {\"$sort\":{\"count\":-1}}, {\"$limit\":10}])  \n",
    "{ \"_id\" : \"mall\", \"count\" : 468 }  \n",
    "{ \"_id\" : \"convenience\", \"count\" : 447 }  \n",
    "{ \"_id\" : \"supermarket\", \"count\" : 317 }  \n",
    "{ \"_id\" : \"car\", \"count\" : 44 }  \n",
    "{ \"_id\" : \"bakery\", \"count\" : 42 }  \n",
    "{ \"_id\" : \"books\", \"count\" : 38 }  \n",
    "{ \"_id\" : \"kiosk\", \"count\" : 37 }  \n",
    "{ \"_id\" : \"bicycle\", \"count\" : 31 }  \n",
    "{ \"_id\" : \"yes\", \"count\" : 31 }  \n",
    "{ \"_id\" : \"clothes\", \"count\" : 28 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Additional Ideas About the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of atrributes of 'shop' related elements (attribute name appearing time >50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: shop, Counts:1869\n",
      "Key: addr:housenumber, Counts:152\n",
      "Key: addr:street, Counts:166\n",
      "Key: name:en, Counts:605\n",
      "Key: name:zh, Counts:517\n",
      "Key: layer, Counts:141\n",
      "Key: opening_hours, Counts:93\n",
      "Key: name, Counts:1600\n",
      "Key: website, Counts:90\n",
      "Key: building:levels, Counts:191\n",
      "Key: building, Counts:447\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "# check if an element has 'tag' tag whose attributes contains 'shop' key\n",
    "def contain_tag_elem_with_shop_attrib(elem):\n",
    "    for sub in elem.iter(\"*\"):\n",
    "        if sub.tag == 'tag':\n",
    "            if 'shop' in sub.attrib['k']:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# accumalate all shop related 'tag' attribute keys\n",
    "shop_keys_dict = defaultdict(int)\n",
    "for _, elem in ET.iterparse('hong-kong_china.osm', events=(\"start\", )):\n",
    "    if elem.tag == \"node\" or elem.tag == \"way\" :\n",
    "        if contain_tag_elem_with_shop_attrib(elem):\n",
    "            for sub in elem.iter(\"tag\"):\n",
    "                shop_keys_dict[sub.attrib['k']] += 1\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# print out those relatively more significant 'tag' attribute keys\n",
    "for key, count in shop_keys_dict.items():\n",
    "    if count > 50:\n",
    "        print \"Key: {}, Counts:{}\".format(key, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suggestion for imporoving shopping related data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hongkong is a well known great place for shopping. It attracts millions of international shoppers every year. It's strategically important to provide shoppers access to quality shopping related information.  \n",
    "One suggestion will be to provide mobile SDKs for developer to build all kinds of social/shopping apps by which a crowsourcing mechanism can be established to collect users generated shopping related content/data. To achieve this goal, two fundamental challenges need to be tackled:  \n",
    "##### 1. Unique identifier for each data source to track data acqusition channel effectiveness  \n",
    "From above data overview, source of most data is unknown. Firstly, this makes it hard to identify the root problem of data quality issue when it happens. Secondly there is no way to track what data sources contribute more data. To facilitate crowsourcing, each data source has to be associated with an unique identifer so that data acquistion channels' effectiveness can be tracked and reviewed subsequently.\n",
    "\n",
    "##### 2. Richness of shopping related data  \n",
    "From above data exploration, very few shop related 'tag' element's keys have more than 50 appearances, which is an indicator of lack of richness for shopping related data. Hopefully by adopting crowsourcing approach, richness can be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "There were few problems encountered throughotu the project, most were data format issues related to standardising 'tag' keys. These issues were easier to address before importing data to MongoDB.  \n",
    "To boost the usage and quality of Hongkong area OSM data, a crowsourcing approah was suggested. Based on characteristics of current OSM data for Hongkong area, two challenges being unique identifier and richness of shopping related info had been identified."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
